{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Ejercicio 1\n",
    "Dado un fichero reto_agua.csv con los datos, realizad los siguientes puntos:\n",
    "• Cargad el csv\n",
    "• Mostrad los primeros 5 datos\n",
    "• Realizad un análisis exploratorio de la estructura y los datos\n",
    "• Extraed la información de la estructura del dataset para responder a las siguientes\n",
    "preguntas:\n",
    "o ¿Veis alguna columna que no consideréis necesaria para el modelo?\n",
    "o ¿Cuántos datos totales hay en dataset?\n",
    "o ¿Hay valores nulos? En ese caso, ¿qué columnas los tienen?\n",
    "o ¿Detectáis alguna columna que tenga datos anómalos? En ese caso,\n",
    "¿cuáles?\n",
    "• Transformad todas las variables objetos en categóricas o numéricas (se pondrán\n",
    "todas las filas nulas como una categoría más). Esto lo podéis hacer con un bucle,\n",
    "con apply, poniendo una a una las columnas, ...\n",
    "• Convertid todas las columnas de columns_object en categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  amount_tsh        funder  gps_height     installer  longitude  \\\n",
      "0  69572      6000.0         Roman        1390         Roman  34.938093   \n",
      "1   8776         0.0       Grumeti        1399       GRUMETI  34.698766   \n",
      "2  34310        25.0  Lottery Club         686  World vision  37.460664   \n",
      "3  67743         0.0        Unicef         263        UNICEF  38.486161   \n",
      "4  19728         0.0   Action In A           0       Artisan  31.130847   \n",
      "\n",
      "    latitude              wpt_name  num_private                    basin  ...  \\\n",
      "0  -9.856322                  none            0               Lake Nyasa  ...   \n",
      "1  -2.147466              Zahanati            0            Lake Victoria  ...   \n",
      "2  -3.821329           Kwa Mahundi            0                  Pangani  ...   \n",
      "3 -11.155298  Zahanati Ya Nanyumbu            0  Ruvuma / Southern Coast  ...   \n",
      "4  -1.825359               Shuleni            0            Lake Victoria  ...   \n",
      "\n",
      "  construction_year  extraction_type management_group payment_type  \\\n",
      "0              1999          gravity       user-group     annually   \n",
      "1              2010          gravity       user-group    never pay   \n",
      "2              2009          gravity       user-group   per bucket   \n",
      "3              1986      submersible       user-group    never pay   \n",
      "4                 0          gravity            other    never pay   \n",
      "\n",
      "  water_quality quality_group  quantity_group source_class  \\\n",
      "0          soft          good          enough  groundwater   \n",
      "1          soft          good    insufficient      surface   \n",
      "2          soft          good          enough      surface   \n",
      "3          soft          good             dry  groundwater   \n",
      "4          soft          good        seasonal      surface   \n",
      "\n",
      "  waterpoint_type_group    status_group  \n",
      "0    communal standpipe      functional  \n",
      "1    communal standpipe      functional  \n",
      "2    communal standpipe      functional  \n",
      "3    communal standpipe  non functional  \n",
      "4    communal standpipe      functional  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(r'reto_agua.csv')\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Respuestas a tus preguntas:\n",
    "\n",
    "### ¿Qué score da el de entrenamiento y con el test?\n",
    "El código anterior calculará y mostrará los scores de entrenamiento y test para cada uno de los tres modelos (Regresión Logística, Random Forest y SVM). El mejor modelo será seleccionado basado en el score de test más alto, y se mostrarán sus scores específicos.\n",
    "\n",
    "Los valores exactos dependerán de tus datos, pero el código imprimirá:\n",
    "- El score de entrenamiento del mejor modelo\n",
    "- El score de test del mejor modelo\n",
    "- La diferencia entre ambos scores\n",
    "\n",
    "### ¿Creéis que puede tener sobreajuste (overfitting) o infraajuste (underfitting)?\n",
    "El código evalúa automáticamente si hay sobreajuste o infraajuste basándose en los siguientes criterios:\n",
    "\n",
    "- **Sobreajuste (overfitting)**: Si la diferencia entre el score de entrenamiento y el score de test es mayor a 0.1 (10%), esto sugiere que el modelo está memorizando los datos de entrenamiento en lugar de aprender patrones generalizables.\n",
    "\n",
    "- **Infraajuste (underfitting)**: Si el score de test es menor a 0.6 (60%), esto indica que el modelo no está capturando adecuadamente la estructura de los datos, posiblemente porque es demasiado simple.\n",
    "\n",
    "- **Bien ajustado**: Si ninguna de las condiciones anteriores se cumple, el modelo probablemente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>basin</th>\n",
       "      <th>...</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>Roman</td>\n",
       "      <td>1390</td>\n",
       "      <td>Roman</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>...</td>\n",
       "      <td>1999</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Grumeti</td>\n",
       "      <td>1399</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>Zahanati</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Lottery Club</td>\n",
       "      <td>686</td>\n",
       "      <td>World vision</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>Kwa Mahundi</td>\n",
       "      <td>0</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Unicef</td>\n",
       "      <td>263</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>Zahanati Ya Nanyumbu</td>\n",
       "      <td>0</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>...</td>\n",
       "      <td>1986</td>\n",
       "      <td>submersible</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Action In A</td>\n",
       "      <td>0</td>\n",
       "      <td>Artisan</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>Shuleni</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>other</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55078</th>\n",
       "      <td>60739</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Germany Republi</td>\n",
       "      <td>1210</td>\n",
       "      <td>CES</td>\n",
       "      <td>37.169807</td>\n",
       "      <td>-3.253847</td>\n",
       "      <td>Area Three Namba 27</td>\n",
       "      <td>0</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>...</td>\n",
       "      <td>1999</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55079</th>\n",
       "      <td>27263</td>\n",
       "      <td>4700.0</td>\n",
       "      <td>Cefa-njombe</td>\n",
       "      <td>1212</td>\n",
       "      <td>Cefa</td>\n",
       "      <td>35.249991</td>\n",
       "      <td>-9.070629</td>\n",
       "      <td>Kwa Yahona Kuvala</td>\n",
       "      <td>0</td>\n",
       "      <td>Rufiji</td>\n",
       "      <td>...</td>\n",
       "      <td>1996</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55080</th>\n",
       "      <td>37057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.017087</td>\n",
       "      <td>-8.750434</td>\n",
       "      <td>Mashine</td>\n",
       "      <td>0</td>\n",
       "      <td>Rufiji</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>swn 80</td>\n",
       "      <td>user-group</td>\n",
       "      <td>monthly</td>\n",
       "      <td>fluoride</td>\n",
       "      <td>fluoride</td>\n",
       "      <td>enough</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55081</th>\n",
       "      <td>31282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Malec</td>\n",
       "      <td>0</td>\n",
       "      <td>Musa</td>\n",
       "      <td>35.861315</td>\n",
       "      <td>-6.378573</td>\n",
       "      <td>Mshoro</td>\n",
       "      <td>0</td>\n",
       "      <td>Rufiji</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>nira/tanira</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55082</th>\n",
       "      <td>26348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>191</td>\n",
       "      <td>World</td>\n",
       "      <td>38.104048</td>\n",
       "      <td>-6.747464</td>\n",
       "      <td>Kwa Mzee Lugawa</td>\n",
       "      <td>0</td>\n",
       "      <td>Wami / Ruvu</td>\n",
       "      <td>...</td>\n",
       "      <td>2002</td>\n",
       "      <td>nira/tanira</td>\n",
       "      <td>user-group</td>\n",
       "      <td>on failure</td>\n",
       "      <td>salty</td>\n",
       "      <td>salty</td>\n",
       "      <td>enough</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55083 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  amount_tsh           funder  gps_height     installer  \\\n",
       "0      69572      6000.0            Roman        1390         Roman   \n",
       "1       8776         0.0          Grumeti        1399       GRUMETI   \n",
       "2      34310        25.0     Lottery Club         686  World vision   \n",
       "3      67743         0.0           Unicef         263        UNICEF   \n",
       "4      19728         0.0      Action In A           0       Artisan   \n",
       "...      ...         ...              ...         ...           ...   \n",
       "55078  60739        10.0  Germany Republi        1210           CES   \n",
       "55079  27263      4700.0      Cefa-njombe        1212          Cefa   \n",
       "55080  37057         0.0              NaN           0           NaN   \n",
       "55081  31282         0.0            Malec           0          Musa   \n",
       "55082  26348         0.0       World Bank         191         World   \n",
       "\n",
       "       longitude   latitude              wpt_name  num_private  \\\n",
       "0      34.938093  -9.856322                  none            0   \n",
       "1      34.698766  -2.147466              Zahanati            0   \n",
       "2      37.460664  -3.821329           Kwa Mahundi            0   \n",
       "3      38.486161 -11.155298  Zahanati Ya Nanyumbu            0   \n",
       "4      31.130847  -1.825359               Shuleni            0   \n",
       "...          ...        ...                   ...          ...   \n",
       "55078  37.169807  -3.253847   Area Three Namba 27            0   \n",
       "55079  35.249991  -9.070629     Kwa Yahona Kuvala            0   \n",
       "55080  34.017087  -8.750434               Mashine            0   \n",
       "55081  35.861315  -6.378573                Mshoro            0   \n",
       "55082  38.104048  -6.747464       Kwa Mzee Lugawa            0   \n",
       "\n",
       "                         basin  ... construction_year  extraction_type  \\\n",
       "0                   Lake Nyasa  ...              1999          gravity   \n",
       "1                Lake Victoria  ...              2010          gravity   \n",
       "2                      Pangani  ...              2009          gravity   \n",
       "3      Ruvuma / Southern Coast  ...              1986      submersible   \n",
       "4                Lake Victoria  ...                 0          gravity   \n",
       "...                        ...  ...               ...              ...   \n",
       "55078                  Pangani  ...              1999          gravity   \n",
       "55079                   Rufiji  ...              1996          gravity   \n",
       "55080                   Rufiji  ...                 0           swn 80   \n",
       "55081                   Rufiji  ...                 0      nira/tanira   \n",
       "55082              Wami / Ruvu  ...              2002      nira/tanira   \n",
       "\n",
       "      management_group payment_type water_quality quality_group  \\\n",
       "0           user-group     annually          soft          good   \n",
       "1           user-group    never pay          soft          good   \n",
       "2           user-group   per bucket          soft          good   \n",
       "3           user-group    never pay          soft          good   \n",
       "4                other    never pay          soft          good   \n",
       "...                ...          ...           ...           ...   \n",
       "55078       user-group   per bucket          soft          good   \n",
       "55079       user-group     annually          soft          good   \n",
       "55080       user-group      monthly      fluoride      fluoride   \n",
       "55081       user-group    never pay          soft          good   \n",
       "55082       user-group   on failure         salty         salty   \n",
       "\n",
       "       quantity_group source_class waterpoint_type_group    status_group  \n",
       "0              enough  groundwater    communal standpipe      functional  \n",
       "1        insufficient      surface    communal standpipe      functional  \n",
       "2              enough      surface    communal standpipe      functional  \n",
       "3                 dry  groundwater    communal standpipe  non functional  \n",
       "4            seasonal      surface    communal standpipe      functional  \n",
       "...               ...          ...                   ...             ...  \n",
       "55078          enough  groundwater    communal standpipe      functional  \n",
       "55079          enough      surface    communal standpipe      functional  \n",
       "55080          enough  groundwater             hand pump      functional  \n",
       "55081    insufficient  groundwater             hand pump      functional  \n",
       "55082          enough  groundwater             hand pump      functional  \n",
       "\n",
       "[55083 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analizamos las columnas eliminamos las que no aportan valor para el análisis\n",
    "\n",
    "encontramos que tanto: id, num_private, recorded_by deben ser borradas del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>basin</th>\n",
       "      <th>region</th>\n",
       "      <th>population</th>\n",
       "      <th>...</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>Roman</td>\n",
       "      <td>1390</td>\n",
       "      <td>Roman</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>none</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>1999</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Grumeti</td>\n",
       "      <td>1399</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>Zahanati</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Mara</td>\n",
       "      <td>280</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Lottery Club</td>\n",
       "      <td>686</td>\n",
       "      <td>World vision</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>Kwa Mahundi</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>Manyara</td>\n",
       "      <td>250</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Unicef</td>\n",
       "      <td>263</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>Zahanati Ya Nanyumbu</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>Mtwara</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>1986</td>\n",
       "      <td>submersible</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Action In A</td>\n",
       "      <td>0</td>\n",
       "      <td>Artisan</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>Shuleni</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Kagera</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>other</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55078</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Germany Republi</td>\n",
       "      <td>1210</td>\n",
       "      <td>CES</td>\n",
       "      <td>37.169807</td>\n",
       "      <td>-3.253847</td>\n",
       "      <td>Area Three Namba 27</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>Kilimanjaro</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>1999</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55079</th>\n",
       "      <td>4700.0</td>\n",
       "      <td>Cefa-njombe</td>\n",
       "      <td>1212</td>\n",
       "      <td>Cefa</td>\n",
       "      <td>35.249991</td>\n",
       "      <td>-9.070629</td>\n",
       "      <td>Kwa Yahona Kuvala</td>\n",
       "      <td>Rufiji</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>1996</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55080</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.017087</td>\n",
       "      <td>-8.750434</td>\n",
       "      <td>Mashine</td>\n",
       "      <td>Rufiji</td>\n",
       "      <td>Mbeya</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>swn 80</td>\n",
       "      <td>user-group</td>\n",
       "      <td>monthly</td>\n",
       "      <td>fluoride</td>\n",
       "      <td>fluoride</td>\n",
       "      <td>enough</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55081</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Malec</td>\n",
       "      <td>0</td>\n",
       "      <td>Musa</td>\n",
       "      <td>35.861315</td>\n",
       "      <td>-6.378573</td>\n",
       "      <td>Mshoro</td>\n",
       "      <td>Rufiji</td>\n",
       "      <td>Dodoma</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>nira/tanira</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55082</th>\n",
       "      <td>0.0</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>191</td>\n",
       "      <td>World</td>\n",
       "      <td>38.104048</td>\n",
       "      <td>-6.747464</td>\n",
       "      <td>Kwa Mzee Lugawa</td>\n",
       "      <td>Wami / Ruvu</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>2002</td>\n",
       "      <td>nira/tanira</td>\n",
       "      <td>user-group</td>\n",
       "      <td>on failure</td>\n",
       "      <td>salty</td>\n",
       "      <td>salty</td>\n",
       "      <td>enough</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55083 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       amount_tsh           funder  gps_height     installer  longitude  \\\n",
       "0          6000.0            Roman        1390         Roman  34.938093   \n",
       "1             0.0          Grumeti        1399       GRUMETI  34.698766   \n",
       "2            25.0     Lottery Club         686  World vision  37.460664   \n",
       "3             0.0           Unicef         263        UNICEF  38.486161   \n",
       "4             0.0      Action In A           0       Artisan  31.130847   \n",
       "...           ...              ...         ...           ...        ...   \n",
       "55078        10.0  Germany Republi        1210           CES  37.169807   \n",
       "55079      4700.0      Cefa-njombe        1212          Cefa  35.249991   \n",
       "55080         0.0              NaN           0           NaN  34.017087   \n",
       "55081         0.0            Malec           0          Musa  35.861315   \n",
       "55082         0.0       World Bank         191         World  38.104048   \n",
       "\n",
       "        latitude              wpt_name                    basin       region  \\\n",
       "0      -9.856322                  none               Lake Nyasa       Iringa   \n",
       "1      -2.147466              Zahanati            Lake Victoria         Mara   \n",
       "2      -3.821329           Kwa Mahundi                  Pangani      Manyara   \n",
       "3     -11.155298  Zahanati Ya Nanyumbu  Ruvuma / Southern Coast       Mtwara   \n",
       "4      -1.825359               Shuleni            Lake Victoria       Kagera   \n",
       "...          ...                   ...                      ...          ...   \n",
       "55078  -3.253847   Area Three Namba 27                  Pangani  Kilimanjaro   \n",
       "55079  -9.070629     Kwa Yahona Kuvala                   Rufiji       Iringa   \n",
       "55080  -8.750434               Mashine                   Rufiji        Mbeya   \n",
       "55081  -6.378573                Mshoro                   Rufiji       Dodoma   \n",
       "55082  -6.747464       Kwa Mzee Lugawa              Wami / Ruvu     Morogoro   \n",
       "\n",
       "       population  ... construction_year extraction_type management_group  \\\n",
       "0             109  ...              1999         gravity       user-group   \n",
       "1             280  ...              2010         gravity       user-group   \n",
       "2             250  ...              2009         gravity       user-group   \n",
       "3              58  ...              1986     submersible       user-group   \n",
       "4               0  ...                 0         gravity            other   \n",
       "...           ...  ...               ...             ...              ...   \n",
       "55078         125  ...              1999         gravity       user-group   \n",
       "55079          56  ...              1996         gravity       user-group   \n",
       "55080           0  ...                 0          swn 80       user-group   \n",
       "55081           0  ...                 0     nira/tanira       user-group   \n",
       "55082         150  ...              2002     nira/tanira       user-group   \n",
       "\n",
       "       payment_type water_quality quality_group quantity_group source_class  \\\n",
       "0          annually          soft          good         enough  groundwater   \n",
       "1         never pay          soft          good   insufficient      surface   \n",
       "2        per bucket          soft          good         enough      surface   \n",
       "3         never pay          soft          good            dry  groundwater   \n",
       "4         never pay          soft          good       seasonal      surface   \n",
       "...             ...           ...           ...            ...          ...   \n",
       "55078    per bucket          soft          good         enough  groundwater   \n",
       "55079      annually          soft          good         enough      surface   \n",
       "55080       monthly      fluoride      fluoride         enough  groundwater   \n",
       "55081     never pay          soft          good   insufficient  groundwater   \n",
       "55082    on failure         salty         salty         enough  groundwater   \n",
       "\n",
       "      waterpoint_type_group    status_group  \n",
       "0        communal standpipe      functional  \n",
       "1        communal standpipe      functional  \n",
       "2        communal standpipe      functional  \n",
       "3        communal standpipe  non functional  \n",
       "4        communal standpipe      functional  \n",
       "...                     ...             ...  \n",
       "55078    communal standpipe      functional  \n",
       "55079    communal standpipe      functional  \n",
       "55080             hand pump      functional  \n",
       "55081             hand pump      functional  \n",
       "55082             hand pump      functional  \n",
       "\n",
       "[55083 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['id', 'num_private', 'recorded_by'], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "revisamos la dimensión, los tipos de datos, los NaN, hacemos un describe y observamos la distribicion de cada una de las variables categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the DataFrame:\n",
      "(55083, 23)\n",
      "\n",
      "Data types of each column:\n",
      "amount_tsh               float64\n",
      "funder                    object\n",
      "gps_height                 int64\n",
      "installer                 object\n",
      "longitude                float64\n",
      "latitude                 float64\n",
      "wpt_name                  object\n",
      "basin                     object\n",
      "region                    object\n",
      "population                 int64\n",
      "public_meeting            object\n",
      "scheme_management         object\n",
      "permit                    object\n",
      "construction_year          int64\n",
      "extraction_type           object\n",
      "management_group          object\n",
      "payment_type              object\n",
      "water_quality             object\n",
      "quality_group             object\n",
      "quantity_group            object\n",
      "source_class              object\n",
      "waterpoint_type_group     object\n",
      "status_group              object\n",
      "dtype: object\n",
      "\n",
      "Missing values in the DataFrame:\n",
      "amount_tsh                  0\n",
      "funder                   3200\n",
      "gps_height                  0\n",
      "installer                3215\n",
      "longitude                   0\n",
      "latitude                    0\n",
      "wpt_name                    2\n",
      "basin                       0\n",
      "region                      0\n",
      "population                  0\n",
      "public_meeting           3178\n",
      "scheme_management        3655\n",
      "permit                   2756\n",
      "construction_year           0\n",
      "extraction_type             0\n",
      "management_group            0\n",
      "payment_type                0\n",
      "water_quality               0\n",
      "quality_group               0\n",
      "quantity_group              0\n",
      "source_class                0\n",
      "waterpoint_type_group       0\n",
      "status_group                0\n",
      "dtype: int64\n",
      "\n",
      "Summary statistics for numerical columns:\n",
      "          amount_tsh    gps_height     longitude      latitude    population  \\\n",
      "count   55083.000000  55083.000000  55083.000000  5.508300e+04  55083.000000   \n",
      "mean      321.614379    671.486230     34.299640 -5.748624e+00    180.286785   \n",
      "std      3065.794824    696.404821      6.142341  2.929462e+00    474.365391   \n",
      "min         0.000000    -90.000000      0.000000 -1.158630e+01      0.000000   \n",
      "25%         0.000000      0.000000     33.176482 -8.566286e+00      0.000000   \n",
      "50%         0.000000    368.000000     34.963928 -5.100971e+00     25.000000   \n",
      "75%        20.000000   1325.000000     37.206957 -3.332487e+00    210.000000   \n",
      "max    350000.000000   2628.000000     40.345193 -2.000000e-08  30500.000000   \n",
      "\n",
      "       construction_year  \n",
      "count       55083.000000  \n",
      "mean         1311.016920  \n",
      "std           948.342454  \n",
      "min             0.000000  \n",
      "25%             0.000000  \n",
      "50%          1986.000000  \n",
      "75%          2004.000000  \n",
      "max          2013.000000  \n",
      "\n",
      "Distribution of categorical variables:\n",
      "\n",
      " funder\n",
      "funder\n",
      "Government Of Tanzania           8383\n",
      "Danida                           2955\n",
      "Hesawa                           1970\n",
      "Rwssp                            1265\n",
      "World Bank                       1252\n",
      "                                 ... \n",
      "Tpp                                 1\n",
      "Paulo Sange                         1\n",
      "Resolute Golden Pride Project       1\n",
      "Swalehe Rajab                       1\n",
      "Warento                             1\n",
      "Name: count, Length: 1853, dtype: int64\n",
      "\n",
      " installer\n",
      "installer\n",
      "DWE            15780\n",
      "Government      1569\n",
      "RWE             1069\n",
      "Commu           1028\n",
      "DANIDA           967\n",
      "               ...  \n",
      "Mzee Omari         1\n",
      "RWI                1\n",
      "Bhoke Mwita        1\n",
      "harison            1\n",
      "J LH CO LTD        1\n",
      "Name: count, Length: 2088, dtype: int64\n",
      "\n",
      " wpt_name\n",
      "wpt_name\n",
      "none                 3487\n",
      "Shuleni              1605\n",
      "Zahanati              752\n",
      "Msikitini             491\n",
      "Kanisani              302\n",
      "                     ... \n",
      "Kwa Petro Ngoha         1\n",
      "Kwa Mzee Swankala       1\n",
      "Kwa Mwanamasabuda       1\n",
      "Kwa Petro Makinga       1\n",
      "Kwa Mboja Nghui         1\n",
      "Name: count, Length: 35004, dtype: int64\n",
      "\n",
      " basin\n",
      "basin\n",
      "Lake Victoria              9259\n",
      "Pangani                    8463\n",
      "Rufiji                     7539\n",
      "Internal                   7228\n",
      "Wami / Ruvu                5718\n",
      "Lake Tanganyika            5690\n",
      "Lake Nyasa                 4835\n",
      "Ruvuma / Southern Coast    4167\n",
      "Lake Rukwa                 2184\n",
      "Name: count, dtype: int64\n",
      "\n",
      " region\n",
      "region\n",
      "Iringa           5171\n",
      "Shinyanga        4347\n",
      "Mbeya            4135\n",
      "Kilimanjaro      4057\n",
      "Morogoro         3706\n",
      "Arusha           3175\n",
      "Kagera           3012\n",
      "Mwanza           2919\n",
      "Pwani            2599\n",
      "Ruvuma           2476\n",
      "Tanga            2474\n",
      "Kigoma           2213\n",
      "Dodoma           1992\n",
      "Singida          1965\n",
      "Tabora           1914\n",
      "Mara             1909\n",
      "Rukwa            1673\n",
      "Mtwara           1604\n",
      "Manyara          1487\n",
      "Lindi            1453\n",
      "Dar es Salaam     802\n",
      "Name: count, dtype: int64\n",
      "\n",
      " public_meeting\n",
      "public_meeting\n",
      "True     47292\n",
      "False     4613\n",
      "Name: count, dtype: int64\n",
      "\n",
      " scheme_management\n",
      "scheme_management\n",
      "VWC                 34459\n",
      "WUG                  4534\n",
      "Water authority      2705\n",
      "WUA                  2644\n",
      "Water Board          2637\n",
      "Parastatal           1478\n",
      "Private operator     1040\n",
      "Company              1024\n",
      "Other                 744\n",
      "SWC                    96\n",
      "Trust                  67\n",
      "Name: count, dtype: int64\n",
      "\n",
      " permit\n",
      "permit\n",
      "True     36155\n",
      "False    16172\n",
      "Name: count, dtype: int64\n",
      "\n",
      " extraction_type\n",
      "extraction_type\n",
      "gravity                      24079\n",
      "nira/tanira                   7513\n",
      "other                         6224\n",
      "submersible                   4537\n",
      "swn 80                        3458\n",
      "mono                          2736\n",
      "india mark ii                 2321\n",
      "afridev                       1728\n",
      "ksb                           1389\n",
      "other - rope pump              434\n",
      "other - swn 81                 222\n",
      "windmill                       110\n",
      "india mark iii                  97\n",
      "other - play pump               84\n",
      "cemo                            81\n",
      "walimi                          36\n",
      "climax                          32\n",
      "other - mkulima/shinyanga        2\n",
      "Name: count, dtype: int64\n",
      "\n",
      " management_group\n",
      "management_group\n",
      "user-group    48584\n",
      "commercial     3521\n",
      "parastatal     1557\n",
      "other           887\n",
      "unknown         534\n",
      "Name: count, dtype: int64\n",
      "\n",
      " payment_type\n",
      "payment_type\n",
      "never pay     23441\n",
      "per bucket     8576\n",
      "unknown        7725\n",
      "monthly        7373\n",
      "on failure     3637\n",
      "annually       3395\n",
      "other           936\n",
      "Name: count, dtype: int64\n",
      "\n",
      " water_quality\n",
      "water_quality\n",
      "soft                  46914\n",
      "salty                  4631\n",
      "unknown                1841\n",
      "milky                   790\n",
      "coloured                436\n",
      "salty abandoned         267\n",
      "fluoride                187\n",
      "fluoride abandoned       17\n",
      "Name: count, dtype: int64\n",
      "\n",
      " quality_group\n",
      "quality_group\n",
      "good        46914\n",
      "salty        4898\n",
      "unknown      1841\n",
      "milky         790\n",
      "colored       436\n",
      "fluoride      204\n",
      "Name: count, dtype: int64\n",
      "\n",
      " quantity_group\n",
      "quantity_group\n",
      "enough          30786\n",
      "insufficient    13679\n",
      "dry              6209\n",
      "seasonal         3634\n",
      "unknown           775\n",
      "Name: count, dtype: int64\n",
      "\n",
      " source_class\n",
      "source_class\n",
      "groundwater    43053\n",
      "surface        11757\n",
      "unknown          273\n",
      "Name: count, dtype: int64\n",
      "\n",
      " waterpoint_type_group\n",
      "waterpoint_type_group\n",
      "communal standpipe    31717\n",
      "hand pump             16459\n",
      "other                  6087\n",
      "improved spring         699\n",
      "cattle trough           114\n",
      "dam                       7\n",
      "Name: count, dtype: int64\n",
      "\n",
      " status_group\n",
      "status_group\n",
      "functional        32259\n",
      "non functional    22824\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the dimensions of the DataFrame\n",
    "print(\"Dimensions of the DataFrame:\")\n",
    "print(df.shape)  # Number of rows and columns\n",
    "\n",
    "# Check the data types of each column\n",
    "print(\"\\nData types of each column:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in the DataFrame:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Summary statistics for numerical columns\n",
    "print(\"\\nSummary statistics for numerical columns:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Distribution of categorical variables\n",
    "print(\"\\nDistribution of categorical variables:\")\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    print(\"\\n\", column)\n",
    "    print(df[column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trataremos los datos faltantes\n",
    "\n",
    "para el caso de la financiera instalador faltantes se completará con 'Desconocido'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>basin</th>\n",
       "      <th>region</th>\n",
       "      <th>population</th>\n",
       "      <th>...</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>Roman</td>\n",
       "      <td>1390</td>\n",
       "      <td>Roman</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>none</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>1999</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Grumeti</td>\n",
       "      <td>1399</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>Zahanati</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Mara</td>\n",
       "      <td>280</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Lottery Club</td>\n",
       "      <td>686</td>\n",
       "      <td>World vision</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>Kwa Mahundi</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>Manyara</td>\n",
       "      <td>250</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Unicef</td>\n",
       "      <td>263</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>Zahanati Ya Nanyumbu</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>Mtwara</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>1986</td>\n",
       "      <td>submersible</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Action In A</td>\n",
       "      <td>0</td>\n",
       "      <td>Artisan</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>Shuleni</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Kagera</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>other</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55078</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Germany Republi</td>\n",
       "      <td>1210</td>\n",
       "      <td>CES</td>\n",
       "      <td>37.169807</td>\n",
       "      <td>-3.253847</td>\n",
       "      <td>Area Three Namba 27</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>Kilimanjaro</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>1999</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55079</th>\n",
       "      <td>4700.0</td>\n",
       "      <td>Cefa-njombe</td>\n",
       "      <td>1212</td>\n",
       "      <td>Cefa</td>\n",
       "      <td>35.249991</td>\n",
       "      <td>-9.070629</td>\n",
       "      <td>Kwa Yahona Kuvala</td>\n",
       "      <td>Rufiji</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>1996</td>\n",
       "      <td>gravity</td>\n",
       "      <td>user-group</td>\n",
       "      <td>annually</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55080</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>0</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>34.017087</td>\n",
       "      <td>-8.750434</td>\n",
       "      <td>Mashine</td>\n",
       "      <td>Rufiji</td>\n",
       "      <td>Mbeya</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>swn 80</td>\n",
       "      <td>user-group</td>\n",
       "      <td>monthly</td>\n",
       "      <td>fluoride</td>\n",
       "      <td>fluoride</td>\n",
       "      <td>enough</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55081</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Malec</td>\n",
       "      <td>0</td>\n",
       "      <td>Musa</td>\n",
       "      <td>35.861315</td>\n",
       "      <td>-6.378573</td>\n",
       "      <td>Mshoro</td>\n",
       "      <td>Rufiji</td>\n",
       "      <td>Dodoma</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>nira/tanira</td>\n",
       "      <td>user-group</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55082</th>\n",
       "      <td>0.0</td>\n",
       "      <td>World Bank</td>\n",
       "      <td>191</td>\n",
       "      <td>World</td>\n",
       "      <td>38.104048</td>\n",
       "      <td>-6.747464</td>\n",
       "      <td>Kwa Mzee Lugawa</td>\n",
       "      <td>Wami / Ruvu</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>2002</td>\n",
       "      <td>nira/tanira</td>\n",
       "      <td>user-group</td>\n",
       "      <td>on failure</td>\n",
       "      <td>salty</td>\n",
       "      <td>salty</td>\n",
       "      <td>enough</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55083 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       amount_tsh           funder  gps_height     installer  longitude  \\\n",
       "0          6000.0            Roman        1390         Roman  34.938093   \n",
       "1             0.0          Grumeti        1399       GRUMETI  34.698766   \n",
       "2            25.0     Lottery Club         686  World vision  37.460664   \n",
       "3             0.0           Unicef         263        UNICEF  38.486161   \n",
       "4             0.0      Action In A           0       Artisan  31.130847   \n",
       "...           ...              ...         ...           ...        ...   \n",
       "55078        10.0  Germany Republi        1210           CES  37.169807   \n",
       "55079      4700.0      Cefa-njombe        1212          Cefa  35.249991   \n",
       "55080         0.0      Desconocido           0   Desconocido  34.017087   \n",
       "55081         0.0            Malec           0          Musa  35.861315   \n",
       "55082         0.0       World Bank         191         World  38.104048   \n",
       "\n",
       "        latitude              wpt_name                    basin       region  \\\n",
       "0      -9.856322                  none               Lake Nyasa       Iringa   \n",
       "1      -2.147466              Zahanati            Lake Victoria         Mara   \n",
       "2      -3.821329           Kwa Mahundi                  Pangani      Manyara   \n",
       "3     -11.155298  Zahanati Ya Nanyumbu  Ruvuma / Southern Coast       Mtwara   \n",
       "4      -1.825359               Shuleni            Lake Victoria       Kagera   \n",
       "...          ...                   ...                      ...          ...   \n",
       "55078  -3.253847   Area Three Namba 27                  Pangani  Kilimanjaro   \n",
       "55079  -9.070629     Kwa Yahona Kuvala                   Rufiji       Iringa   \n",
       "55080  -8.750434               Mashine                   Rufiji        Mbeya   \n",
       "55081  -6.378573                Mshoro                   Rufiji       Dodoma   \n",
       "55082  -6.747464       Kwa Mzee Lugawa              Wami / Ruvu     Morogoro   \n",
       "\n",
       "       population  ... construction_year extraction_type management_group  \\\n",
       "0             109  ...              1999         gravity       user-group   \n",
       "1             280  ...              2010         gravity       user-group   \n",
       "2             250  ...              2009         gravity       user-group   \n",
       "3              58  ...              1986     submersible       user-group   \n",
       "4               0  ...                 0         gravity            other   \n",
       "...           ...  ...               ...             ...              ...   \n",
       "55078         125  ...              1999         gravity       user-group   \n",
       "55079          56  ...              1996         gravity       user-group   \n",
       "55080           0  ...                 0          swn 80       user-group   \n",
       "55081           0  ...                 0     nira/tanira       user-group   \n",
       "55082         150  ...              2002     nira/tanira       user-group   \n",
       "\n",
       "       payment_type water_quality quality_group quantity_group source_class  \\\n",
       "0          annually          soft          good         enough  groundwater   \n",
       "1         never pay          soft          good   insufficient      surface   \n",
       "2        per bucket          soft          good         enough      surface   \n",
       "3         never pay          soft          good            dry  groundwater   \n",
       "4         never pay          soft          good       seasonal      surface   \n",
       "...             ...           ...           ...            ...          ...   \n",
       "55078    per bucket          soft          good         enough  groundwater   \n",
       "55079      annually          soft          good         enough      surface   \n",
       "55080       monthly      fluoride      fluoride         enough  groundwater   \n",
       "55081     never pay          soft          good   insufficient  groundwater   \n",
       "55082    on failure         salty         salty         enough  groundwater   \n",
       "\n",
       "      waterpoint_type_group    status_group  \n",
       "0        communal standpipe      functional  \n",
       "1        communal standpipe      functional  \n",
       "2        communal standpipe      functional  \n",
       "3        communal standpipe  non functional  \n",
       "4        communal standpipe      functional  \n",
       "...                     ...             ...  \n",
       "55078    communal standpipe      functional  \n",
       "55079    communal standpipe      functional  \n",
       "55080             hand pump      functional  \n",
       "55081             hand pump      functional  \n",
       "55082             hand pump      functional  \n",
       "\n",
       "[55083 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['funder'].fillna('Desconocido', inplace=True)\n",
    "df[['funder', 'installer']] = df[['funder', 'installer']].fillna('Desconocido')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Respuestas a tus preguntas:\n",
    "\n",
    "### ¿Qué score da el de entrenamiento y con el test?\n",
    "El código anterior calculará y mostrará los scores de entrenamiento y test para cada uno de los tres modelos (Regresión Logística, Random Forest y SVM). El mejor modelo será seleccionado basado en el score de test más alto, y se mostrarán sus scores específicos.\n",
    "\n",
    "### ¿Creéis que puede tener sobreajuste (overfitting) o infraajuste (underfitting)?\n",
    "Para determinar si hay sobreajuste o infraajuste, el código analiza la diferencia entre el score de entrenamiento y el score de test:\n",
    "\n",
    "- **Sobreajuste (overfitting)**: Ocurre cuando el modelo tiene un rendimiento significativamente mejor en los datos de entrenamiento que en los de prueba (diferencia > 0.1). Esto indica que el modelo ha \"memorizado\" los datos de entrenamiento pero no generaliza bien.\n",
    "\n",
    "- **Infraajuste (underfitting)**: Ocurre cuando el modelo tiene un rendimiento bajo tanto en entrenamiento como en prueba (score de test < 0.6). Esto sugiere que el modelo es demasiado simple para capturar la complejidad de los datos.\n",
    "\n",
    "- **Bien ajustado**: Si la diferencia entre los scores de entrenamiento y test es pequeña y ambos scores son razonablemente altos, el modelo está bien ajustado.\n",
    "\n",
    "Para mejorar el análisis, podrías considerar usar paquetes adicionales como:\n",
    "- `scikit-learn` para técnicas de validación cruzada\n",
    "- `xgboost` o `lightgbm` para modelos más avanzados\n",
    "- `yellowbrick` para visualizaciones específicas de machine learning\n",
    "- `mlxtend` para análisis adicionales de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Ejercicio 2\n",
    "Ahora, vamos a entrenar el modelo:\n",
    "\n",
    "Pero antes vamos a convertir las variables categóricas para podes entrenar el modelo.\n",
    "• Dividid los datos del df  en variable independiente y target\n",
    "• Dividid el modelo en un conjunto de datos para el test (20%) y otro para el train (80%)\n",
    "y random_state=42\n",
    "• Entrenad tres modelos con los datos de train, validadlo con el test y seleccionad\n",
    "el que mejor resultado obtiene.\n",
    "Una vez hecho esto, responded a las siguientes preguntas:\n",
    "• ¿Qué score da el de entrenamiento y con el test?\n",
    "• ¿Creéis que puede tener sobreajuste (overfitting) o infraajuste (underfitting)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases del target: ['functional' 'non functional']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/anaconda-ai-2024.04-py310/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo: Regresión Logística\n",
      "Reporte de clasificación (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82      6559\n",
      "           1       0.78      0.60      0.68      4458\n",
      "\n",
      "    accuracy                           0.77     11017\n",
      "   macro avg       0.77      0.74      0.75     11017\n",
      "weighted avg       0.77      0.77      0.76     11017\n",
      "\n",
      "\n",
      "Modelo: Random Forest\n",
      "Reporte de clasificación (Test):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89      6559\n",
      "           1       0.86      0.79      0.82      4458\n",
      "\n",
      "    accuracy                           0.86     11017\n",
      "   macro avg       0.86      0.85      0.85     11017\n",
      "weighted avg       0.86      0.86      0.86     11017\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 94\u001b[0m\n\u001b[1;32m     85\u001b[0m results \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModelo\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScore Train\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScore Test\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiferencia\u001b[39m\u001b[38;5;124m'\u001b[39m: []\n\u001b[1;32m     90\u001b[0m }\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# Entrenar modelo\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# Evaluar en train y test\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     y_pred_train \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-ai-2024.04-py310/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-ai-2024.04-py310/lib/python3.10/site-packages/sklearn/pipeline.py:420\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    419\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 420\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-ai-2024.04-py310/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-ai-2024.04-py310/lib/python3.10/site-packages/sklearn/svm/_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[0;32m--> 250\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-ai-2024.04-py310/lib/python3.10/site-packages/sklearn/svm/_base.py:371\u001b[0m, in \u001b[0;36mBaseLibSVM._sparse_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    357\u001b[0m kernel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_kernels\u001b[38;5;241m.\u001b[39mindex(kernel)\n\u001b[1;32m    359\u001b[0m libsvm_sparse\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[1;32m    361\u001b[0m (\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[1;32m    364\u001b[0m     dual_coef_data,\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[0;32m--> 371\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm_sparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibsvm_sparse_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_class_weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32msklearn/svm/_libsvm_sparse.pyx:219\u001b[0m, in \u001b[0;36msklearn.svm._libsvm_sparse.libsvm_sparse_train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/anaconda-ai-2024.04-py310/lib/python3.10/site-packages/scipy/sparse/_compressed.py:27\u001b[0m, in \u001b[0;36m_cs_matrix.__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_cs_matrix\u001b[39;00m(_data_matrix, _minmax_mixin, IndexMixin):\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    base array/matrix class for compressed row- and column-oriented arrays/matrices\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg1, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     28\u001b[0m         _data_matrix\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m issparse(arg1):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "# Identificar columnas categóricas y numéricas\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Asumiendo que la última columna es el target\n",
    "target_col = df.columns[-1]\n",
    "if target_col in categorical_cols:\n",
    "    categorical_cols.remove(target_col)\n",
    "if target_col in numerical_cols:\n",
    "    numerical_cols.remove(target_col)\n",
    "\n",
    "# Preparar variables independientes (X) y dependiente (y)\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# Si el target es categórico, convertirlo a numérico\n",
    "if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y)\n",
    "    print(f\"Clases del target: {label_encoder.classes_}\")\n",
    "\n",
    "# Crear preprocesadores para columnas categóricas y numéricas\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "# Combinar preprocesadores\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento (80%) y prueba (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear pipelines para cada modelo\n",
    "# Modelo 1: Regresión Logística\n",
    "pipe1 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=100))\n",
    "])\n",
    "\n",
    "# Modelo 2: Random Forest\n",
    "pipe2 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Modelo 3: Support Vector Machine\n",
    "pipe3 = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "# Entrenar y evaluar los modelos\n",
    "models = [\n",
    "    ('Regresión Logística', pipe1),\n",
    "    ('Random Forest', pipe2),\n",
    "    ('SVM', pipe3)\n",
    "]\n",
    "\n",
    "results = {\n",
    "    'Modelo': [],\n",
    "    'Score Train': [],\n",
    "    'Score Test': [],\n",
    "    'Diferencia': []\n",
    "}\n",
    "\n",
    "for name, model in models:\n",
    "    # Entrenar modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluar en train y test\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    score_train = accuracy_score(y_train, y_pred_train)\n",
    "    score_test = accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results['Modelo'].append(name)\n",
    "    results['Score Train'].append(score_train)\n",
    "    results['Score Test'].append(score_test)\n",
    "    results['Diferencia'].append(score_train - score_test)\n",
    "    \n",
    "    print(f\"\\nModelo: {name}\")\n",
    "    print(f\"Reporte de clasificación (Test):\")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nComparación de modelos:\")\n",
    "print(results_df)\n",
    "\n",
    "# Visualizar resultados\n",
    "plt.figure(figsize=(10, 6))\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(models))\n",
    "\n",
    "plt.bar(index, results_df['Score Train'], bar_width, label='Train')\n",
    "plt.bar(index + bar_width, results_df['Score Test'], bar_width, label='Test')\n",
    "\n",
    "plt.xlabel('Modelo')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparación de modelos: Train vs Test')\n",
    "plt.xticks(index + bar_width/2, results_df['Modelo'])\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Seleccionar el mejor modelo basado en el score de test\n",
    "best_model_index = results_df['Score Test'].idxmax()\n",
    "best_model_name = results_df.loc[best_model_index, 'Modelo']\n",
    "best_train_score = results_df.loc[best_model_index, 'Score Train']\n",
    "best_test_score = results_df.loc[best_model_index, 'Score Test']\n",
    "difference = best_train_score - best_test_score\n",
    "\n",
    "print(f\"\\nEl mejor modelo es: {best_model_name}\")\n",
    "print(f\"Score de entrenamiento: {best_train_score:.4f}\")\n",
    "print(f\"Score de test: {best_test_score:.4f}\")\n",
    "print(f\"Diferencia entre train y test: {difference:.4f}\")\n",
    "\n",
    "# Evaluación de overfitting/underfitting\n",
    "if difference > 0.1:\n",
    "    print(\"Posible sobreajuste (overfitting): El modelo tiene un rendimiento significativamente mejor en los datos de entrenamiento que en los de prueba.\")\n",
    "elif best_test_score < 0.6:\n",
    "    print(\"Posible infraajuste (underfitting): El modelo tiene un rendimiento bajo tanto en entrenamiento como en prueba.\")\n",
    "else:\n",
    "    print(\"El modelo parece estar bien ajustado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 2.3. Ejercicio 3\n",
    "Seleccionad las 21 variables que más influyen en la predicción y entrenad de nuevo el\n",
    "modelo. ¿Mejora?\n",
    "Usadlas para sacar los scoring ['accuracy', 'precision', 'recall'] del conjunto de train:\n",
    "• ¿Interpreta accuracy?\n",
    "• ¿Interpreta precision?\n",
    "• ¿Interpreta recall?\n",
    "• ¿Predice mejor los positivos o los negativos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User\n",
    "Seleccionad las 21 variables del df que más influyen en la predicción y entrenad de nuevo el modelo. ¿Mejora? Usadlas para sacar los scoring ['accuracy', 'precision', 'recall'] del conjunto de train: • ¿Interpreta accuracy? • ¿Interpreta precision? • ¿Interpreta recall? • ¿Predice mejor los positivos o los negativos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistant\n",
    "# Selección de las 21 variables más influyentes y entrenamiento del modelo\n",
    "\n",
    "Para seleccionar las variables más influyentes en la predicción y entrenar un nuevo modelo, utilizaré técnicas de selección de características y evaluaré si el modelo mejora con este subconjunto de variables. Luego analizaré las métricas de evaluación solicitadas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suponiendo que ya tenemos un DataFrame df con variables predictoras X y variable objetivo y\n",
    "# Si no están definidos, deberías cargar tus datos y preparar X e y\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar un modelo inicial para determinar la importancia de las características\n",
    "modelo_inicial = RandomForestClassifier(random_state=42)\n",
    "modelo_inicial.fit(X_train, y_train)\n",
    "\n",
    "# Obtener la importancia de las características\n",
    "importancias = modelo_inicial.feature_importances_\n",
    "indices = np.argsort(importancias)[::-1]\n",
    "\n",
    "# Mostrar las importancias de las características\n",
    "print(\"Importancia de características:\")\n",
    "for i in range(min(X_train.shape[1], 30)):  # Mostrar las primeras 30 o menos\n",
    "    print(f\"{i+1}. {X_train.columns[indices[i]]}: {importancias[indices[i]]:.4f}\")\n",
    "\n",
    "# Seleccionar las 21 características más importantes\n",
    "selector = SelectFromModel(modelo_inicial, max_features=21, threshold=-np.inf)\n",
    "selector.fit(X_train, y_train)\n",
    "X_train_reducido = selector.transform(X_train)\n",
    "X_test_reducido = selector.transform(X_test)\n",
    "\n",
    "# Ver qué características se seleccionaron\n",
    "caracteristicas_seleccionadas = X_train.columns[selector.get_support()]\n",
    "print(\"\\nCaracterísticas seleccionadas:\", caracteristicas_seleccionadas.tolist())\n",
    "\n",
    "# Entrenar un nuevo modelo con las características seleccionadas\n",
    "modelo_reducido = RandomForestClassifier(random_state=42)\n",
    "modelo_reducido.fit(X_train_reducido, y_train)\n",
    "\n",
    "# Evaluar el modelo original en el conjunto de prueba\n",
    "y_pred_original = modelo_inicial.predict(X_test)\n",
    "accuracy_original = accuracy_score(y_test, y_pred_original)\n",
    "precision_original = precision_score(y_test, y_pred_original)\n",
    "recall_original = recall_score(y_test, y_pred_original)\n",
    "\n",
    "# Evaluar el modelo reducido en el conjunto de prueba\n",
    "y_pred_reducido = modelo_reducido.predict(X_test_reducido)\n",
    "accuracy_reducido = accuracy_score(y_test, y_pred_reducido)\n",
    "precision_reducido = precision_score(y_test, y_pred_reducido)\n",
    "recall_reducido = recall_score(y_test, y_pred_reducido)\n",
    "\n",
    "# Comparar resultados\n",
    "print(\"\\nComparación de modelos (conjunto de prueba):\")\n",
    "print(f\"Modelo original - Accuracy: {accuracy_original:.4f}, Precision: {precision_original:.4f}, Recall: {recall_original:.4f}\")\n",
    "print(f\"Modelo reducido - Accuracy: {accuracy_reducido:.4f}, Precision: {precision_reducido:.4f}, Recall: {recall_reducido:.4f}\")\n",
    "\n",
    "# Evaluar el modelo reducido en el conjunto de entrenamiento (como se solicita)\n",
    "y_pred_train = modelo_reducido.predict(X_train_reducido)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "precision_train = precision_score(y_train, y_pred_train)\n",
    "recall_train = recall_score(y_train, y_pred_train)\n",
    "\n",
    "print(\"\\nMétricas del modelo reducido en el conjunto de entrenamiento:\")\n",
    "print(f\"Accuracy: {accuracy_train:.4f}\")\n",
    "print(f\"Precision: {precision_train:.4f}\")\n",
    "print(f\"Recall: {recall_train:.4f}\")\n",
    "\n",
    "# Matriz de confusión para analizar mejor el rendimiento\n",
    "conf_matrix = confusion_matrix(y_train, y_pred_train)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Negativo', 'Positivo'], \n",
    "            yticklabels=['Negativo', 'Positivo'])\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor Real')\n",
    "plt.title('Matriz de Confusión (Conjunto de Entrenamiento)')\n",
    "plt.show()\n",
    "\n",
    "# Calcular métricas específicas para positivos y negativos\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "especificidad = tn / (tn + fp)  # Tasa de verdaderos negativos\n",
    "print(f\"\\nEspecificidad (tasa de verdaderos negativos): {especificidad:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Interpretación de las métricas\n",
    "\n",
    "### Accuracy (Exactitud)\n",
    "- **Interpretación**: La accuracy mide la proporción de predicciones correctas (tanto positivas como negativas) sobre el total de predicciones. Es decir, (TP + TN) / (TP + TN + FP + FN).\n",
    "- Es una métrica general que indica qué tan bien el modelo clasifica correctamente ambas clases.\n",
    "- Sin embargo, puede ser engañosa cuando las clases están desbalanceadas, ya que un modelo que siempre predice la clase mayoritaria puede tener una alta accuracy sin ser realmente útil.\n",
    "\n",
    "### Precision (Precisión)\n",
    "- **Interpretación**: La precision mide la proporción de predicciones positivas correctas sobre el total de predicciones positivas. Es decir, TP / (TP + FP).\n",
    "- Indica qué tan confiables son las predicciones positivas del modelo.\n",
    "- Una alta precisión significa que cuando el modelo predice la clase positiva, generalmente está en lo correcto.\n",
    "- Es especialmente importante cuando el costo de un falso positivo es alto.\n",
    "\n",
    "### Recall (Sensibilidad)\n",
    "- **Interpretación**: El recall mide la proporción de casos positivos reales que fueron correctamente identificados por el modelo. Es decir, TP / (TP + FN).\n",
    "- Indica la capacidad del modelo para encontrar todos los casos positivos.\n",
    "- Un alto recall significa que el modelo es bueno detectando la clase positiva.\n",
    "- Es especialmente importante cuando el costo de un falso negativo es alto.\n",
    "\n",
    "### ¿Predice mejor los positivos o los negativos?\n",
    "\n",
    "Para determinar si el modelo predice mejor los positivos o los negativos, debemos comparar:\n",
    "- **Para positivos**: El recall (sensibilidad) nos indica qué tan bien predice los casos positivos.\n",
    "- **Para negativos**: La especificidad (TN/(TN+FP)) nos indica qué tan bien predice los casos negativos.\n",
    "\n",
    "Si el recall es mayor que la especificidad, el modelo es mejor prediciendo casos positivos. Si la especificidad es mayor que el recall, el modelo es mejor prediciendo casos negativos.\n",
    "\n",
    "La matriz de confusión visualizada en el código nos ayuda a ver claramente esta comparación y determinar en qué clase el modelo tiene mejor rendimiento.\n",
    "\n",
    "Para mejorar aún más este análisis, podrías utilizar paquetes como `scikit-learn`, `pandas`, `numpy`, `matplotlib`, `seaborn` y `imbalanced-learn` (si hay desbalance de clases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 2.4. Ejercicio 4\n",
    "Validad la correlación con uno o más gráficos con las columnas ['amount_tsh', 'funder',\n",
    "'gps_height', 'installer', 'longitude', 'latitude', 'num_private', 'basin','status_group'].\n",
    "Después, haced un gráfico, el que consideréis adecuado, para detectar outliers en\n",
    "population y gps_height ¿alguno tiene outliers? De ser así, eliminadlos con el método de\n",
    "Inter cuartil con la columna o columnas con datos atípicos. ¿El modelo ha mejorado?\n",
    "Recordad que hay que volver a sacar los valores x e y (test y train).\n",
    "Para terminar, usad la búsqueda de hiperparámetro para ajustar al modelo seleccionado\n",
    "(buscad en https://scikit-learn.org/ o en la página del modelo usado). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Interpretación de las métricas\n",
    "\n",
    "### Accuracy (Exactitud)\n",
    "- **Interpretación**: La accuracy mide la proporción de predicciones correctas (tanto positivas como negativas) sobre el total de predicciones. Es decir, (TP + TN) / (TP + TN + FP + FN).\n",
    "- Es una métrica general que indica qué tan bien el modelo clasifica correctamente ambas clases.\n",
    "- Sin embargo, puede ser engañosa cuando las clases están desbalanceadas, ya que un modelo que siempre predice la clase mayoritaria puede tener una alta accuracy sin ser realmente útil.\n",
    "\n",
    "### Precision (Precisión)\n",
    "- **Interpretación**: La precision mide la proporción de predicciones positivas correctas sobre el total de predicciones positivas. Es decir, TP / (TP + FP).\n",
    "- Indica qué tan confiables son las predicciones positivas del modelo.\n",
    "- Una alta precisión significa que cuando el modelo predice la clase positiva, generalmente está en lo correcto.\n",
    "- Es especialmente importante cuando el costo de un falso positivo es alto.\n",
    "\n",
    "### Recall (Sensibilidad)\n",
    "- **Interpretación**: El recall mide la proporción de casos positivos reales que fueron correctamente identificados por el modelo. Es decir, TP / (TP + FN).\n",
    "- Indica la capacidad del modelo para encontrar todos los casos positivos.\n",
    "- Un alto recall significa que el modelo es bueno detectando la clase positiva.\n",
    "- Es especialmente importante cuando el costo de un falso negativo es alto.\n",
    "\n",
    "### ¿Predice mejor los positivos o los negativos?\n",
    "\n",
    "Para determinar si el modelo predice mejor los positivos o los negativos, debemos comparar:\n",
    "- **Para positivos**: El recall (sensibilidad) nos indica qué tan bien predice los casos positivos.\n",
    "- **Para negativos**: La especificidad (TN/(TN+FP)) nos indica qué tan bien predice los casos negativos.\n",
    "\n",
    "Si el recall es mayor que la especificidad, el modelo es mejor prediciendo casos positivos. Si la especificidad es mayor que el recall, el modelo es mejor prediciendo casos negativos.\n",
    "\n",
    "La matriz de confusión visualizada en el código nos ayuda a ver claramente esta comparación y determinar en qué clase el modelo tiene mejor rendimiento.\n",
    "\n",
    "Para mejorar aún más este análisis, podrías utilizar paquetes como `scikit-learn`, `pandas`, `numpy`, `matplotlib`, `seaborn` y `imbalanced-learn` (si hay desbalance de clases)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User\n",
    "Validad la correlación con uno o más gráficos con las columnas del df ['amount_tsh', 'funder', 'gps_height', 'installer', 'longitude', 'latitude', 'num_private', 'basin','status_group']. Después, haced un gráfico, el que consideréis adecuado, para detectar outliers en population y gps_height ¿alguno tiene outliers? De ser así, eliminadlos con el método de Inter cuartil con la columna o columnas con datos atípicos. ¿El modelo ha mejorado? Recordad que hay que volver a sacar los valores x e y (test y train)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistant\n",
    "# Análisis de correlación y detección de outliers\n",
    "\n",
    "Voy a realizar un análisis de correlación entre las variables solicitadas, detectar outliers en las columnas 'population' y 'gps_height', y evaluar si la eliminación de outliers mejora el rendimiento del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Suponiendo que tenemos un DataFrame df con las columnas mencionadas\n",
    "# Si no está definido, deberías cargar tus datos\n",
    "\n",
    "# 1. Análisis de correlación\n",
    "# Primero, necesitamos convertir las variables categóricas a numéricas para la correlación\n",
    "df_corr = df[['amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private', 'basin', 'funder', 'installer', 'status_group']].copy()\n",
    "\n",
    "# Convertir variables categóricas a numéricas\n",
    "for col in ['basin', 'funder', 'installer', 'status_group']:\n",
    "    le = LabelEncoder()\n",
    "    df_corr[col] = le.fit_transform(df_corr[col])\n",
    "\n",
    "# Matriz de correlación\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr_matrix = df_corr.corr()\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.title('Matriz de Correlación')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de dispersión para visualizar relaciones entre variables numéricas y status_group\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i, col in enumerate(['amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private']):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    sns.scatterplot(data=df, x=col, y='status_group', alpha=0.6)\n",
    "    plt.title(f'{col} vs status_group')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Detección de outliers en population y gps_height\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Boxplot para population\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(y=df['population'])\n",
    "plt.title('Boxplot de Population')\n",
    "plt.ylabel('Population')\n",
    "\n",
    "# Boxplot para gps_height\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=df['gps_height'])\n",
    "plt.title('Boxplot de GPS Height')\n",
    "plt.ylabel('GPS Height')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Histogramas para visualizar la distribución\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Histograma para population\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df['population'], kde=True)\n",
    "plt.title('Distribución de Population')\n",
    "plt.xlabel('Population')\n",
    "\n",
    "# Histograma para gps_height\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df['gps_height'], kde=True)\n",
    "plt.title('Distribución de GPS Height')\n",
    "plt.xlabel('GPS Height')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Eliminación de outliers usando el método IQR\n",
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# Verificar si hay outliers en population\n",
    "population_outliers = df[(df['population'] < df['population'].quantile(0.25) - 1.5 * (df['population'].quantile(0.75) - df['population'].quantile(0.25))) | \n",
    "                         (df['population'] > df['population'].quantile(0.75) + 1.5 * (df['population'].quantile(0.75) - df['population'].quantile(0.25)))]\n",
    "print(f\"Número de outliers en population: {len(population_outliers)}\")\n",
    "\n",
    "# Verificar si hay outliers en gps_height\n",
    "gps_height_outliers = df[(df['gps_height'] < df['gps_height'].quantile(0.25) - 1.5 * (df['gps_height'].quantile(0.75) - df['gps_height'].quantile(0.25))) | \n",
    "                         (df['gps_height'] > df['gps_height'].quantile(0.75) + 1.5 * (df['gps_height'].quantile(0.75) - df['gps_height'].quantile(0.25)))]\n",
    "print(f\"Número de outliers en gps_height: {len(gps_height_outliers)}\")\n",
    "\n",
    "# Eliminar outliers de las columnas que los tienen\n",
    "df_no_outliers = df.copy()\n",
    "if len(population_outliers) > 0:\n",
    "    df_no_outliers = remove_outliers_iqr(df_no_outliers, 'population')\n",
    "    print(f\"Registros después de eliminar outliers de population: {len(df_no_outliers)}\")\n",
    "    \n",
    "if len(gps_height_outliers) > 0:\n",
    "    df_no_outliers = remove_outliers_iqr(df_no_outliers, 'gps_height')\n",
    "    print(f\"Registros después de eliminar outliers de gps_height: {len(df_no_outliers)}\")\n",
    "\n",
    "# 4. Entrenar y evaluar modelos antes y después de eliminar outliers\n",
    "# Preparar datos para el modelo original\n",
    "X = df.drop('status_group', axis=1)\n",
    "y = df['status_group']\n",
    "\n",
    "# Codificar variables categóricas si es necesario\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar modelo original\n",
    "modelo_original = RandomForestClassifier(random_state=42)\n",
    "modelo_original.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar modelo original\n",
    "y_pred_original = modelo_original.predict(X_test)\n",
    "accuracy_original = accuracy_score(y_test, y_pred_original)\n",
    "precision_original = precision_score(y_test, y_pred_original, average='weighted')\n",
    "recall_original = recall_score(y_test, y_pred_original, average='weighted')\n",
    "\n",
    "print(\"\\nResultados del modelo original:\")\n",
    "print(f\"Accuracy: {accuracy_original:.4f}\")\n",
    "print(f\"Precision: {precision_original:.4f}\")\n",
    "print(f\"Recall: {recall_original:.4f}\")\n",
    "\n",
    "# Preparar datos para el modelo sin outliers\n",
    "X_no_outliers = df_no_outliers.drop('status_group', axis=1)\n",
    "y_no_outliers = df_no_outliers['status_group']\n",
    "\n",
    "# Codificar variables categóricas si es necesario\n",
    "X_no_outliers_encoded = pd.get_dummies(X_no_outliers)\n",
    "\n",
    "# Asegurarse de que X_no_outliers_encoded tenga las mismas columnas que X_encoded\n",
    "for col in X_encoded.columns:\n",
    "    if col not in X_no_outliers_encoded.columns:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de correlación y detección de outliers\r\n",
    "\r\n",
    "Voy a realizar un análisis de correlación entre las variables solicitadas, detectar outliers en las columnas 'population' y 'gps_height', y evaluar si la eliminación de outliers mejora el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Suponiendo que tenemos un DataFrame df con las columnas mencionadas\n",
    "# Si no está definido, deberías cargar tus datos\n",
    "\n",
    "# 1. Análisis de correlación\n",
    "# Primero, necesitamos convertir las variables categóricas a numéricas para la correlación\n",
    "df_corr = df[['amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private', 'basin', 'funder', 'installer', 'status_group']].copy()\n",
    "\n",
    "# Convertir variables categóricas a numéricas\n",
    "for col in ['basin', 'funder', 'installer', 'status_group']:\n",
    "    le = LabelEncoder()\n",
    "    df_corr[col] = le.fit_transform(df_corr[col])\n",
    "\n",
    "# Matriz de correlación\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr_matrix = df_corr.corr()\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.title('Matriz de Correlación')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de dispersión para visualizar relaciones entre variables numéricas y status_group\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i, col in enumerate(['amount_tsh', 'gps_height', 'longitude', 'latitude', 'num_private']):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    sns.scatterplot(data=df, x=col, y='status_group', alpha=0.6)\n",
    "    plt.title(f'{col} vs status_group')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Detección de outliers en population y gps_height\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Boxplot para population\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(y=df['population'])\n",
    "plt.title('Boxplot de Population')\n",
    "plt.ylabel('Population')\n",
    "\n",
    "# Boxplot para gps_height\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=df['gps_height'])\n",
    "plt.title('Boxplot de GPS Height')\n",
    "plt.ylabel('GPS Height')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Histogramas para visualizar la distribución\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Histograma para population\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df['population'], kde=True)\n",
    "plt.title('Distribución de Population')\n",
    "plt.xlabel('Population')\n",
    "\n",
    "# Histograma para gps_height\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df['gps_height'], kde=True)\n",
    "plt.title('Distribución de GPS Height')\n",
    "plt.xlabel('GPS Height')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Eliminación de outliers usando el método IQR\n",
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# Verificar si hay outliers en population\n",
    "population_outliers = df[(df['population'] < df['population'].quantile(0.25) - 1.5 * (df['population'].quantile(0.75) - df['population'].quantile(0.25))) | \n",
    "                         (df['population'] > df['population'].quantile(0.75) + 1.5 * (df['population'].quantile(0.75) - df['population'].quantile(0.25)))]\n",
    "print(f\"Número de outliers en population: {len(population_outliers)}\")\n",
    "\n",
    "# Verificar si hay outliers en gps_height\n",
    "gps_height_outliers = df[(df['gps_height'] < df['gps_height'].quantile(0.25) - 1.5 * (df['gps_height'].quantile(0.75) - df['gps_height'].quantile(0.25))) | \n",
    "                         (df['gps_height'] > df['gps_height'].quantile(0.75) + 1.5 * (df['gps_height'].quantile(0.75) - df['gps_height'].quantile(0.25)))]\n",
    "print(f\"Número de outliers en gps_height: {len(gps_height_outliers)}\")\n",
    "\n",
    "# Eliminar outliers de las columnas que los tienen\n",
    "df_no_outliers = df.copy()\n",
    "if len(population_outliers) > 0:\n",
    "    df_no_outliers = remove_outliers_iqr(df_no_outliers, 'population')\n",
    "    print(f\"Registros después de eliminar outliers de population: {len(df_no_outliers)}\")\n",
    "    \n",
    "if len(gps_height_outliers) > 0:\n",
    "    df_no_outliers = remove_outliers_iqr(df_no_outliers, 'gps_height')\n",
    "    print(f\"Registros después de eliminar outliers de gps_height: {len(df_no_outliers)}\")\n",
    "\n",
    "# 4. Entrenar y evaluar modelos antes y después de eliminar outliers\n",
    "# Preparar datos para el modelo original\n",
    "X = df.drop('status_group', axis=1)\n",
    "y = df['status_group']\n",
    "\n",
    "# Codificar variables categóricas si es necesario\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar modelo original\n",
    "modelo_original = RandomForestClassifier(random_state=42)\n",
    "modelo_original.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar modelo original\n",
    "y_pred_original = modelo_original.predict(X_test)\n",
    "accuracy_original = accuracy_score(y_test, y_pred_original)\n",
    "precision_original = precision_score(y_test, y_pred_original, average='weighted')\n",
    "recall_original = recall_score(y_test, y_pred_original, average='weighted')\n",
    "\n",
    "print(\"\\nResultados del modelo original:\")\n",
    "print(f\"Accuracy: {accuracy_original:.4f}\")\n",
    "print(f\"Precision: {precision_original:.4f}\")\n",
    "print(f\"Recall: {recall_original:.4f}\")\n",
    "\n",
    "# Preparar datos para el modelo sin outliers\n",
    "X_no_outliers = df_no_outliers.drop('status_group', axis=1)\n",
    "y_no_outliers = df_no_outliers['status_group']\n",
    "\n",
    "# Codificar variables categóricas si es necesario\n",
    "X_no_outliers_encoded = pd.get_dummies(X_no_outliers)\n",
    "\n",
    "# Asegurarse de que X_no_outliers_encoded tenga las mismas columnas que X_encoded\n",
    "for col in X_encoded.columns:\n",
    "    if col not in X_no_outliers_encoded.columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-ai-2024.04-py310",
   "language": "python",
   "name": "conda-env-anaconda-ai-2024.04-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
