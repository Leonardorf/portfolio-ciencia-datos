{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Ejercicio 1\n",
    "Dado un fichero reto_agua.csv con los datos, realizad los siguientes puntos:\n",
    "• Cargad el csv\n",
    "• Mostrad los primeros 5 datos\n",
    "• Realizad un análisis exploratorio de la estructura y los datos\n",
    "• Extraed la información de la estructura del dataset para responder a las siguientes\n",
    "preguntas:\n",
    "o ¿Veis alguna columna que no consideréis necesaria para el modelo?\n",
    "o ¿Cuántos datos totales hay en dataset?\n",
    "o ¿Hay valores nulos? En ese caso, ¿qué columnas los tienen?\n",
    "o ¿Detectáis alguna columna que tenga datos anómalos? En ese caso,\n",
    "¿cuáles?\n",
    "• Transformad todas las variables objetos en categóricas o numéricas (se pondrán\n",
    "todas las filas nulas como una categoría más). Esto lo podéis hacer con un bucle,\n",
    "con apply, poniendo una a una las columnas, ...\n",
    "• Convertid todas las columnas de columns_object en categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Ejercicio 2\n",
    "Ahora, vamos a entrenar el modelo:\n",
    "• Dividid los datos en variable independiente y target\n",
    "• Dividid el modelo en un conjunto de datos para el test (20%) y otro para el train (80%)\n",
    "y random_state=42\n",
    "• Entrenad varios modelos con los datos de train, validadlo con el test y seleccionad\n",
    "el que mejor resultado obtiene.\n",
    "Una vez hecho esto, responded a las siguientes preguntas:\n",
    "• ¿Qué score da el de entrenamiento y con el test?\n",
    "• ¿Creéis que puede tener sobreajuste (overfitting) o infraajuste (underfitting)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Ejercicio 3\n",
    "Seleccionad las 21 variables que más influyen en la predicción y entrenad de nuevo el\n",
    "modelo. ¿Mejora?\n",
    "Usadlas para sacar los scoring ['accuracy', 'precision', 'recall'] del conjunto de train:\n",
    "• ¿Interpreta accuracy?\n",
    "• ¿Interpreta precision?\n",
    "• ¿Interpreta recall?\n",
    "• ¿Predice mejor los positivos o los negativos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Ejercicio 4\n",
    "Validad la correlación con uno o más gráficos con las columnas ['amount_tsh', 'funder',\n",
    "'gps_height', 'installer', 'longitude', 'latitude', 'num_private', 'basin','status_group'].\n",
    "Después, haced un gráfico, el que consideréis adecuado, para detectar outliers en\n",
    "population y gps_height ¿alguno tiene outliers? De ser así, eliminadlos con el método de\n",
    "Inter cuartil con la columna o columnas con datos atípicos. ¿El modelo ha mejorado?\n",
    "Recordad que hay que volver a sacar los valores x e y (test y train).\n",
    "Para terminar, usad la búsqueda de hiperparámetro para ajustar al modelo seleccionado\n",
    "(buscad en https://scikit-learn.org/ o en la página del modelo usado). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
